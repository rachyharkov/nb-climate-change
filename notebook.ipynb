{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"gnb_normalize_dataset_fix.csv\")\n",
    "df = pd.read_csv(\"dataset_iklim.csv\", delimiter=\";\", thousands=\".\", decimal=\",\")\n",
    "\n",
    "# set column names\n",
    "df.columns = ['tanggal', 'tn', 'tx', 'tavg', 'rh_avg', 'rr', 'ss', 'ff_x', 'ddd_x', 'ff_avg', 'ddd_car']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 8888: data tidak terukur\n",
    "- 9999: Tidak Ada Data (tidak dilakukan pengukuran)\n",
    "- Tn: Temperatur minimum (°C)\n",
    "- Tx: Temperatur maksimum (°C)\n",
    "- Tavg: Temperatur rata-rata (°C)\n",
    "- RH_avg: Kelembapan rata-rata (%)\n",
    "- RR: Curah hujan (mm)\n",
    "- ss: Lamanya penyinaran matahari (jam)\n",
    "- ff_x: Kecepatan angin maksimum (m/s)\n",
    "- ddd_x: Arah angin saat kecepatan maksimum (°)\n",
    "- ff_avg: Kecepatan angin rata-rata (m/s)\n",
    "- ddd_car: Arah angin terbanyak (°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete row with 8888 value\n",
    "df.drop(df[df['rr'] == 8888].index, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelling df\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df_labelled = df.apply(le.fit_transform)\n",
    "df_labelled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min max normalization sklearn\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_labelled)\n",
    "df_norm = scaler.transform(df_labelled)\n",
    "df_norm = pd.DataFrame(df_norm, columns=df_labelled.columns)\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "corr = df_norm.corr()\n",
    "corr\n",
    "\n",
    "# plot the heatmap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# increase the size of the plot\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "sns.heatmap(corr,\n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns,\n",
    "        cmap=\"YlGnBu\",\n",
    "        annot=True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  variabel bebas\n",
    "x = df_norm.drop([\"RR\",\"Tanggal\"], axis = 1)\n",
    "x.head()\n",
    "\n",
    "#variabel tidak bebas\n",
    "y = df_norm[\"RR\"]\n",
    "x.head()\n",
    "\n",
    "# classification \n",
    "# please install scikit library \n",
    "# pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 3)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model using gaussian naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# create the model\n",
    "model = GaussianNB()\n",
    "\n",
    "# train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# # predict the model\n",
    "# y_pred = model.predict(x_test)\n",
    "# y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the y_test based on separation dataset\n",
    "# np.array(y_test)\n",
    "\n",
    "# show the confusion matrix based on the prediction result \n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)\n",
    "\n",
    "#evaluate performance from the confusion matrix \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "\n",
    "# this value will show all probability for each predicted class \n",
    "NB_train.predict_proba(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff7573f1831cb99fcd99b3a81494c967ce7bb90e5d2619f47f81c5d8e958e1df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
